我在设计大语言模型的推理引擎，C++ 实现，支持多节点多卡并行计算，节点内 TP + PP，节点间只 PP。

* Server 使用 engine.add_request() 添加请求，随即 Engine 内部进行运算，每一轮的 step 存到某个队列内，由 Server 自行取用。
* Engine 利用 Scheduler 将 request 组成 request_batch 送给 Worker。（Scheduler 负责决策，Engine 负责根据决策准备 ModelInputBatch（包含 tokens, Block Tables 等）并分发给 Worker(s)。）
* Worker 利用 Communicator 和 Layer 进行节点内的 TP 计算（Worker 执行其拥有的 Layer，而这些 Layer 如果是张量并行的，会使用注入的 IntraNodeTensorParallelCommunicator 来进行 TP 组内部的通信（如 AllReduce, AllGather）。）
* Worker 完成其节点内的 TP 计算后，将其（作为流水线一个阶段的）输出结果报告/返回给其所在节点的 Engine
* 不同节点上的 Engine 实例之间。一个节点的 Engine (我们称之为 Engine_A，负责阶段 S) 在收到其内部 Worker 的结果后，会使用 InterNodePipelineCommunicator 将这个结果 Send 给负责下一个阶段 S+1 的另一个节点上的 Engine (我们称之为 Engine_B)。同样，Engine_B 会使用这个 Communicator 来 Recv 来自 Engine_A 的数据。

**阶段一：构思与规划 (Idea & Planning)**

1.  **明确想法与目标 (Define Idea & Goals):**
    *   **核心功能:** 大语言模型推理引擎
    *   **目标用户:** 中国使用国产计算卡的小型企业、个人、实验室
    *   **价值主张:** 大吞吐、高速、异构
    *   **范围界定 (Scope):** 初期版本仅支持核心token推理，日后再实现Server部分。

2.  **市场调研与竞品分析 (Market Research & Competitor Analysis):** 
    *   **现有产品:** SGLang、vLLM、TensorRT-LLM、MindIE、[llama.cpp]。
    *   **差异化和优势:** 见现有产品调研。

3.  **需求分析 (Requirements Analysis):**
    *   **功能需求:** 系统必须具备模型参数装载、单节点多卡推理、多节点多卡推理。
    *   **非功能需求:** 1）吞吐量（Throughput）
、首Token时延（TTFT, Time to First Token）、每Token生成时延（TPOT, Time Per Output Token）；2）显存占用（GPU Memory Usage）；3）可扩展性（可扩展到多设备，模块内技术替换）；4）可维护性（计算卡掉线）。
    *   **约束条件:** 开发语言（C++）、目标平台（Linux）、依赖的硬件（NVIDIA GPU、NPU、MOSS）、时间限制（5个月）等。

4.  **可行性分析 (Feasibility Study):**
    *   **技术可行性:** 现有框架对于开发者来说存在众多技术难点。
    *   **资源可行性:** 人力紧张（只有作者一个人）；时间紧张（年底完成）。
    *   **风险评估:** 存在可能无法攻克技术点的情况，也有可能在开发中出现新的框架技术直接让本产品失去存在意义。技术问题只能花时间去硬啃，出现新产品的话就装鸵鸟，假装看不见。

**阶段二：设计 (Design)**

1.  **架构设计 (Architectural Design):**
    *   **高层架构:** 分层架构
    *   **模块划分:** 
        * **Server:** 与用户交互（本版本不实现）
        * **Engine:** 进行模型 token 推理，不断自回归生成数据
        * **InterNodeComm:** 进行 Engine 之间的数据通信，相当于节点间进行流水线并行。
        * **Scheduler:** Engine 内调度子模块，负责调度用户请求，选择哪些请求进入 Engine 当前计算轮次。
        * **Worker:** Engine 内真正用于计算子模块，Engine 维护多个 Worker 进行张量并行计算（TP）。每个 Worker 负责管理一个外部设备进行内存管理、计算。
        * **Layer:** 用于 Worker 内的函数运算，下面有Function，根据 Worker 提供的设备类型，选取对应的函数装备。
        * **Function:** 抽象接口，是 Layer 调用的具体函数，负责实际的计算，跟据不同的设备有不同的实现。
        * **MemAllocator:** 负责管理 Worker 的设备内存，提供给 Layer 的参数（Weight）以及运算过程中产生的中间值（Activation）。
        * **KVCacheManager:** 负责管理 Worker 设备计算过程中产生的 KVCache，应该是需要协同 MemAllocator 一同工作。

2.  **详细设计 (Detailed Design):**
    *   **类设计:** 设计核心类，包括其属性、方法、继承关系、组合关系。可以考虑使用UML类图。
    *   **接口设计 (API Design):** 模块间、类间的接口。力求清晰、稳定、易用。
    *   **算法设计:** FlashAttention、blockAttention、MemPool、microBatch、
    *   **错误处理与日志策略:** GPU掉线处理（本版本不实现）Timeout 异常、记录日志。

3.  **原型开发 (Prototyping):** (可选，但推荐)
    *   针对核心功能或高风险模块开发一个快速原型，用于验证技术方案、设计思路或用户界面。

**阶段三：实现 (Implementation)**

1.  **环境搭建 (Environment Setup):**
    *   **IDE/编辑器:** Visual Studio, CLion, VS Code, Qt Creator等。
    *   **编译器:** MSVC, GCC, Clang。
    *   **构建系统:** CMake (强烈推荐，跨平台), Make, Meson, Bazel等。
    *   **版本控制系统:** Git (几乎是标配)。
    *   **包管理器:** Conan, vcpkg (用于管理第三方依赖)。
    *   **调试工具:** GDB, LLDB, Visual Studio Debugger。

2.  **编码 (Coding):**
    *   **遵循编码规范:** 统一代码风格，提高可读性和可维护性（例如 Google C++ Style Guide, LLVM Coding Standards）。
    *   **模块化开发:** 根据设计，分模块进行开发。
    *   **面向对象/泛型编程:** 充分利用C++的特性。
    *   **内存管理:** 使用RAII原则，智能指针 (std::unique_ptr, std::shared_ptr) 来避免内存泄漏。
    *   **异常安全:** 编写异常安全的代码。
    *   **代码复用:** 避免重复造轮子，合理使用库和模板。
    *   **单元测试驱动开发 (TDD) / 并行编写单元测试:** 为每个模块或重要函数编写单元测试。使用测试框架如 Google Test, Catch2。

3.  **代码审查 (Code Review):**
    *   团队成员互相审查代码，发现潜在问题，提高代码质量，知识共享。

4.  **集成 (Integration):**
    *   逐步将各个模块集成起来，解决集成过程中出现的问题。
    *   **持续集成 (CI):** 使用 Jenkins, GitLab CI/CD, GitHub Actions 等工具，在代码提交后自动构建、测试。

**阶段四：测试 (Testing)**

1.  **单元测试 (Unit Testing):** 验证最小代码单元（函数、类）的正确性。
2.  **集成测试 (Integration Testing):** 验证模块之间交互的正确性。
3.  **系统测试 (System Testing):** 在完整系统环境下，验证系统是否满足所有需求（功能和非功能）。
4.  **用户验收测试 (UAT - User Acceptance Testing):** 由最终用户或代表进行测试，确认项目是否满足其期望。
5.  **性能测试、安全测试、压力测试等:** 根据非功能需求进行。
6.  **Bug修复:** 记录、跟踪并修复测试过程中发现的缺陷。

**阶段五：部署 (Deployment)**

1.  **准备部署环境:** 生产服务器、操作系统、依赖库等。
2.  **打包与分发:**
    *   **编译发布版本 (Release Build):** 开启优化，关闭调试信息。
    *   **创建安装包:** 使用 NSIS, Inno Setup (Windows), CPack (CMake自带) 等。
    *   **容器化:** 使用 Docker 将应用及其依赖打包成镜像。
3.  **部署上线:** 将应用部署到生产环境。
4.  **配置管理:** 管理不同环境（开发、测试、生产）的配置。
5.  **上线后监控:** 监控系统运行状态、性能指标、错误日志。

**阶段六：维护与迭代 (Maintenance & Iteration)**

1.  **监控与日志分析:** 持续监控系统运行，分析日志，及时发现问题。
2.  **Bug修复:** 修复用户反馈的或监控发现的Bug。
3.  **用户支持:** 提供用户手册、FAQ，解答用户疑问。
4.  **性能优化:** 根据实际运行情况，对瓶颈进行优化。
5.  **功能迭代:** 根据用户反馈和新的业务需求，规划并开发新版本，重复上述2-5阶段。
6.  **文档更新:** 随着代码的变更，及时更新设计文档、用户手册等。

**贯穿始终的重要事项:**

*   **版本控制 (Version Control):** 从项目开始就使用Git，并遵循良好的分支策略（如Gitflow）。
*   **项目管理 (Project Management):**
    *   **方法论:** 选择合适的项目管理方法（敏捷如Scrum/Kanban，或瀑布，或混合）。
    *   **工具:** Jira, Trello, Asana, Redmine等。
    *   **沟通:** 保持团队内外良好沟通。
*   **文档编写 (Documentation):**
    *   **需求文档、设计文档、API文档、用户手册、运维手册。**
    *   **代码注释。**
    *   使用Doxygen等工具从代码生成文档。
*   **持续学习 (Continuous Learning):** C++语言本身在不断发展，新的库和工具也层出不穷，保持学习非常重要。
*   **关注代码质量:** 使用静态分析工具 (Clang-Tidy, Cppcheck, PVS-Studio)、代码格式化工具 (Clang-Format)、代码覆盖率工具。

这个流程是一个理想化的模型，实际项目中可能会根据具体情况进行调整和裁剪。对于小型个人项目，某些步骤可能会简化，但核心思想是相通的。祝你的C++项目顺利！

# Engine 与 Worker 交互
当前 Engine 可以向 Worker 发布以下命令：
* INIT：worker 准备好设备环境，准备好模型、模型加载参数
* INFER：worker 进行推理
* SHUTDONW：worker 释放自己的资源

Engine 使用 `promise` 和 `future` 来向 Worker 发布命令以及等待 Worker 传回处理完毕的信息。使用示例如下
```
#include <iostream>
#include <future>

void asyncFunction(std::promise<int>&& promiseObj) {
    // 模拟一些计算
    int result = 10;
    promiseObj.set_value(result); // 设置结果
}

int main() {
    std::promise<int> myPromise; // 创建一个promise对象
    std::future<int> futureObj = myPromise.get_future(); // 获取future对象

    std::thread t(asyncFunction, std::move(myPromise)); // 启动新线程执行异步函数

    // 等待异步操作完成并获取结果
    int value = futureObj.get();
    std::cout << "Result: " << value << std::endl;

    t.join(); // 确保线程已经结束
    return 0;
}
```
# Function的设计
函数是无状态的，并且函数的种类组合数量会非常庞大（硬件类型 x 数据精度 x 操作类型）。采用**注册表模式 (Registry Pattern)** 来管理所有的函数。

函数由 `\include\function.h` 里面定义的函数指针，由对应的 Layer 来使用对应种类的函数。同一操作类型的函数接口是相同的，所以由 Worker 根据配置文件获取对应硬件类型、数据精度的函数，赋给 Layer 的函数指针。
```
// function.h

using LinearFuncPtr = void (*)(void *y, void *X, void *W, int W_in, int W_out, int num);
```

核心思想：
### 函数注册表（FuncRegistry）
在`\include\registry.h`内，FuncRegistry 是一个模板类，由模板提供运算的种类，由下面的全局注册表（OpRegistry）声明，在编译阶段完成。FuncRegistry内部有个 `std::map<std::tuple<int, int>, FuncPtrT> registry_map_;` 当对应种类的函数注册到对应种类的 FuncRegistry 后，通过 `FuncPtrT Get(int device, int dtype)` 获取对应的 device、dtype 的函数指针。
```
template <typename FuncPtrT>
class FuncRegistry {
public:
    void Register(int device, int dtype, FuncPtrT ptr) {
        registry_map_[std::make_tuple(device, dtype)] = ptr;
    }

    FuncPtrT Get(int device, int dtype) const {
        auto it = registry_map_.find(std::make_tuple(device, dtype));
        if (it != registry_map_.end()) {
            return it->second;
        }
        
        throw std::runtime_error("Function implementation not found for device/dtype combination.");
        return nullptr;
    }

private:
    std::map<std::tuple<int, int>, FuncPtrT> registry_map_;
};
```

### 全局注册表 ( OpRegistry )
在 `\include\registry.h` 创建了一个全局的单例注册表管理器，名为 `OpRegistry` 。这个管理器内部为每一种操作类型（如 Linear 、 Attention 、 RMSNorm 、 Add 等）维护一个专门的函数指针注册表 ( FuncRegistry )。
```
class OpRegistry {
public:
    static OpRegistry& Instance() {
        static OpRegistry instance;
        return instance;
    }
    
    // 禁止拷贝和赋值
    OpRegistry(const OpRegistry&) = delete;
    OpRegistry& operator=(const OpRegistry&) = delete;

    // 提供对特定类型函数指针注册表的访问
    FuncRegistry<LinearFuncPtr>& Linear() { return linear_registry_; }
    // FuncRegistry<AttentionFuncPtr>& Attention() { return attention_registry_; }
    // FuncRegistry<RMSNormFuncPtr>& RMSNorm() { return rmsnorm_registry_; }
    // ...

private:
    OpRegistry() = default;

    FuncRegistry<LinearFuncPtr> linear_registry_;
    // FuncRegistry<AttentionFuncPtr> attention_registry_;
    // FuncRegistry<RMSNormFuncPtr> rmsnorm_registry_;
    // ...
};
```

Worker 通过下面的方式从注册表内得到特定种类、设备、数据类型的计算函数。
```
LinearFuncPtr linear_func = OpRegistry::Instance().Linear().Get(CUDA, FLOAT32);
std::unique_ptr<Layer> linear_layer = std::make_unique<Linear>(linear_func);
```
### 自动注册
所有的函数都在 `src/ops/xxxx/xxxx_device.*` 实现。xxxx 代表某一种类的函数文件夹，文件夹下是各种不同的设备对这个函数的支持。
```
./ops/
├── attention
│   └── attention_cpu.cpp
└── linear
    ├── linear_cpu.cpp
    └── linear_cuda.cu
```
在 `\include\registry.h` 有一个宏，用于我们实现一个函数后，完成自动注册。
```
#define REGISTER_OP_FUNCTION(OP_NAME, DEVICE, DTYPE, FUNC_PTR) \
    namespace { \
        struct Registrar_##OP_NAME##_##DEVICE##_##DTYPE { \
            Registrar_##OP_NAME##_##DEVICE##_##DTYPE() { \
                OpRegistry::Instance().OP_NAME().Register(DEVICE, DTYPE, FUNC_PTR); \
            } \
        }; \
        static Registrar_##OP_NAME##_##DEVICE##_##DTYPE registrar_instance; \
    }

```
在 `src/ops/xxxx/xxxx_device.*` 内，每完成一个函数便进行一次注册。
```
void cpu_fp32_linear_exec(void *y, void *X, void *W, int W_in, int W_out, int num)
{
    // 缩放因子
    float alpha = 1.0;
    float beta = 0.0;  // C 的初始权重
    // 调用 OpenBLAS 的 SGEMM 函数
    cblas_sgemm(CblasColMajor, CblasTrans, CblasNoTrans,
                (float *)W_out, num, (float *)W_in,          // 矩阵维度
                alpha,
                (float *)W, W_in,                            // 矩阵 W 和列主布局步长
                (float *)X, W_in,                            // 矩阵 X 和列主布局步长
                beta,            // beta
                (float *)y, (float *)W_out);                 // 结果矩阵 C 和列主布局步长
}

REGISTER_OP_FUNCTION(Linear, CPU, FLOAT32, cpu_fp32_linear_exec);
```
